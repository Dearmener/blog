---
title: 本地大模型部署方案 Ollama
description: 在本地使用大模型
pubDate: Mar 24 2024
heroImage: /254932576-0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7.png
tags:
  - 大模型
---

我也不知道为什么要在本地跑 llama2，但是目前跑的还不错，可以当做本地翻译软件使用。
使用 ollama 下载 llama2 模型后，在 「沉浸式翻译」和 「OpenAI translation」中可以调用，

> 使用沉浸式翻译需要用下面的命令启动 llama2:
> 
> OLLAMA_ORIGINS="*" ollama serve


